# 神经网络模型分词实验

## 实验目的

中文分词指的是中文在基本文法上有其特殊性而存在的分词。中文分词是自然语言处理中文部分的基础，很多下游任务都需要基于分词的基础进行，分词的质量也一定程度上决定了下游任务的准确性。本次实验拟通过神经网络算法，在中文数据集PKU 与 MSR上实现中分分词模型。主要的实验目的包括：

- 掌握中文分词（Tokenization）任务的基本解决思路。学习自然语言处理数据集的处理与词表的构建方法。
- 借助基于神经网络的方法实现中文分词。掌握CNN，RNN，LSTM等神经网络基本结构的用法。通过查阅文献学习Bi-LSTM、Bi-LSTM-CRF等扩展模型的基本思想和算法实现。
- 体会神经网络各种超参数对模型效果的影响。
- 掌握评价分词好坏的评价指标。学会分析Bad Case以及产生的原因，并尝试寻找解决的思路与办法。

## 实验原理

中文分词是中文文本处理的一个基础步骤，也是中文人机自然语言交互的基础模块。不同于英文的是，中文句子中没有词的界限，因此在进行中文自然语言处理时，通常需要先进行分词，分词效果将直接影响词性、句法树等模块的效果。

在人机自然语言交互中，成熟的中文分词算法能够达到更好的自然语言处理效果，帮助计算机理解复杂的中文语言。在构建中文自然语言对话系统时，结合语言学不断优化，训练出了一套具有较好分词效果的算法模型，为机器更好地理解中文自然语言奠定了基础。

随着网络信息的急剧增长给人们搜索信息带来一定的困难，中文分词到底对搜索引擎有多大影响？对于搜索引擎来说，最重要的并不是找到所有结果，因为在上百亿的网页中找到所有结果没有太多的意义，没有人能看得完，最重要的是把最相关的结果排在最前面，这也称为相关度排序。中文分词的准确与否，常常直接影响到对搜索结果的相关度排序。

本次实验针对中文分词技术，采用Bi-LSTM和Bi-LSTM-CRF神经网络方法来实现中文分词。针对Bi-LSTM模型展开实验。

### Bi-LSTM模型

LSTM的全称是Long Short-Term Memory，它是RNN（Recurrent Neural Network）的一种。LSTM由于其设计的特点，非常适合用于对时序数据的建模，如文本数据。Bi-LSTM是Bi-directional Long Short-Term Memory的缩写，是由前向LSTM与后向LSTM组合而成。两者在自然语言处理任务中都常被用来建模上下文信息。

将词的表示组合成句子的表示，可以采用相加的方法，即将所有词的表示进行加和，或者取平均等方法，但是这些方法没有考虑到词语在句子中前后顺序。使用LSTM模型可以更好的捕捉到较长距离的依赖关系。因为LSTM通过训练过程可以学到记忆哪些信息和遗忘哪些信息。

但是利用LSTM对句子进行建模还存在一个问题：无法编码从后到前的信息。因此，Bi-LSTM诞生了，解决了该问题。通过Bi-LSTM可以更好地捕捉双向的语义依赖。前向的LSTM与后向的LSTM结合成Bi-LSTM。

### Bi-LSTM+CRF模型

条件随机场（Conditional Random Field，CRF）是自然语言处理的基础模型，广泛应用于中文分词、命名实体识别、词性标注等标注场景。条件随机场是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型，其特点是假设输出随机变量构成马尔可夫随机场，条件随机场可以用于不同的预测问题。

条件随机场的特点：理论上较为完善的序列标记模型，无标记偏执问题；兼具判别模型和无向图模型的优点，特征设计灵活、无需要求特征独立；条件随机场模型训练代价大、复杂度高。

CRF是解决序列问题最终输出序列的传统算法模型，正常的序列标注采用SoftMax针对序列每个位置完成一次多分类，但CRF是针对整个序列选择出一条最优的序列分类结果，考虑了序列整体输出的特征。

因此，条件随机场CRF与深度学习结合，产生了Bi-LSTM-CRF、Bi-LSTM-CNN-CRF等模型，在中文分词、命名实体识别、词性标注也取得不错的效果。

## 实验方案

### Bi-LSTM模型分词

我们知道，中文分词的本质是一个序列标注问题，对于序列标注问题我们需要确定标记的类别。常用的标记方法采用“SBME”标注方法：“S”（Single）表示单个字作为词；“B”（Begin）表示一个词语的开始第一个字；“E”（End）表示一个词语结尾最后一个字；“M”（Middle）表示一个单词中间的那些字。这样“S”，“B”，“E”，“M”组成了标注序列的符号集合。针对Bi-LSTM模型进行中文分词的具体内容和步骤如下：

1. 首先需要针对数据集进行构建语料库，将文本数据集生成训练语料需要的List，最外层List是整个训练数据集文本，该List中每个元素是个List，代表每句话（每一行）的文本，该内层List中的元素是每句话文本的中文字符。

2. 根据生成的训练语料List，根据“SBME”标注方法，生成与之对应的标记List，根据训练数据集中语料空格分词的特性，以及“SBME”四种标签的含义，便可以构造出字符级别的跟语料库对应的标签语料。

3. 构建中文字符集合和标签集合的字典，将字符与索引建立联系，便于后续模型对其进行处理。

4. 实现Bi-LSTM模型，首先根据输入的词表，构建Embedding层，将Embedding Size和Hidden Size大小都设置为128，其中Bi-LSTM的层数作为超参数，观察不同层数模型的效果差异。最后再通过一层全连接层将输出的尺寸和词表大小一致。

5. 划分训练集为训练和验证集，便于保存训练过程中最优的模型。同时设置训练的batch_size = 64，学习率lr = 0.001，训练轮次epoches = 50。

6. 利用测试集测试模型的效果并对一些case进行分析。

### Bi-LSTM+CRF模型分词

Bi-LSTM+CRF模型在Bi-LSTM的模型基础上，在输出的地方添加一个词表大小×词表大小的转移矩阵，注意这里的词表相对Bi-LSTM需要多添加“\<start>”和“\<end>”字符。

这里同时将CRF模型也实现对比测试。

在测试解码的过程中，则需要维特比算法来求解最佳的输出解码序列。

实验除了与传统算法进行对比，同时也将与一些开源的中文分词库进行性能比对，主要包括jieba，pkuseg，THULAC三个经典的中文分词库进行比较。

**Jieba**：经典的中文分词包，支持四种分词模式：

1. 精确模式，试图将句子最精确地切开，适合文本分析；

2. 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；

3. 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。

4. paddle模式，利用PaddlePaddle深度学习框架，训练序列标注（双向GRU）网络模型实现分词。

**Pkuseg**：一个多领域中文分词工具包。

1. 多领域分词。不同于以往的通用中文分词工具，此工具包同时致力于为不同领域的数据提供个性化的预训练模型。根据待分词文本的领域特点，用户可以自由地选择不同的模型。 目前支持了新闻领域，网络领域，医药领域，旅游领域，以及混合领域的分词预训练模型。在使用中，如果用户明确待分词的领域，可加载对应的模型进行分词。如果用户无法确定具体领域，推荐使用在混合领域上训练的通用模型。

2. 更高的分词准确率。相比于其他的分词工具包，当使用相同的训练数据和测试数据，pkuseg可以取得更高的分词准确率。

3. 支持用户自训练模型。支持用户使用全新的标注数据进行训练。

4. 支持词性标注。

**THULAC**：（THU Lexical Analyzer for Chinese）由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，具有中文分词和词性标注功能。

1. 能力强。利用我们集成的目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字）训练而成，模型标注能力强大。

2. 准确率高。该工具包在标准数据集Chinese Treebank（CTB5）上分词的F1值可达97.3％，词性标注的F1值可达到92.9％，与该数据集上最好方法效果相当。

3. 速度较快。同时进行分词和词性标注速度为300KB/s，每秒可处理约15万字。只进行分词速度可达到1.3MB/s。

## 实验结果

### PKU数据集

实验评价指标主要针对准确率，召回率，F1分数以及处理速度进行评估。

首先，我们针对Bi-LSTM和Bi-LSTM+CRF不同层数结构进行实验比对，在PKU数据集上实验评测的结果如下表所示：

| 模型，层数     | 准确率     | 召回率     | F1分数     |
| -------------- | ---------- | ---------- | ---------- |
| Bi-LSTM，1     | 0.9071     | 0.9054     | 0.9061     |
| Bi-LSTM，2     | 0.9189     | 0.9168     | 0.9176     |
| Bi-LSTM，3     | **0.9248** | **0.9236** | **0.9240** |
| Bi-LSTM+CRF，1 | **0.9366** | **0.9354** | **0.9358** |
| Bi-LSTM+CRF，2 | 0.9233     | 0.9224     | 0.9227     |
| Bi-LSTM+CRF，3 | 0.9217     | 0.9215     | 0.9215     |

本次实验采用最优的Bi-LSTM结构和Bi-LSTM+CRF结构，同传统的分词算法一同对比，以及经典的分词算法库分词结构进行对比，在PKU数据集上的模型的几大评价指标如下表所示：

| 模型            | 准确率 | 召回率 | F1分数 |
| --------------- | ------ | ------ | ------ |
| Uni-Gram        | 0.8550 | 0.9342 | 0.8928 |
| Uni-Gram+规则   | 0.9111 | 0.9496 | 0.9300 |
| HMM             | 0.7936 | 0.8090 | 0.8012 |
| CRF             | 0.9409 | 0.9396 | 0.9400 |
| **Bi-LSTM**     | 0.9248 | 0.9236 | 0.9240 |
| **Bi-LSTM+CRF** | 0.9366 | 0.9354 | 0.9358 |
| jieba           | 0.8559 | 0.7896 | 0.8214 |
| pkuseg          | 0.9512 | 0.9224 | 0.9366 |
| THULAC          | 0.9287 | 0.9295 | 0.9291 |

注意，这里的规则指的是通过匹配到一些特殊的字，如“年”，“月”，“日”等字同时前面是数字，那么就将这些数字和关键字组合为一个词语。或者是“万”，“亿”等表示数量的词做相似的处理等。也就是通过人为加规则的方法来实现。

### MSR数据集

实验评价指标主要针对准确率，召回率，F1分数以及处理速度进行评估。

首先，我们针对Bi-LSTM和Bi-LSTM+CRF不同层数结构进行实验比对，在MSR数据集上的实验评测的结果如下表所示：

| 模型，层数     | 准确率     | 召回率     | F1分数     |
| -------------- | ---------- | ---------- | ---------- |
| Bi-LSTM，1     | 0.9434     | 0.9437     | 0.9435     |
| Bi-LSTM，2     | **0.9624** | **0.9625** | **0.9624** |
| Bi-LSTM，3     | 0.9623     | 0.9624     | 0.9622     |
| Bi-LSTM+CRF，1 | 0.9566     | 0.9568     | 0.9566     |
| Bi-LSTM+CRF，2 | 0.9631     | 0.9632     | 0.9631     |
| Bi-LSTM+CRF，3 | **0.9631** | **0.9632** | **0.9632** |

实验采用最优的Bi-LSTM结构和Bi-LSTM+CRF结构，同传统的分词算法一同对比，以及经典的分词算法库分词结构进行对比，在MSR数据集上的模型的几大评价指标如下表所示：

| 模型            | 准确率 | 召回率 | F1分数 |
| --------------- | ------ | ------ | ------ |
| Uni-Gram        | 0.9119 | 0.9633 | 0.9369 |
| Uni-Gram+规则   | 0.9129 | 0.9634 | 0.9375 |
| HMM             | 0.7786 | 0.8189 | 0.7983 |
| CRF             | 0.9675 | 0.9676 | 0.9675 |
| **Bi-LSTM**     | 0.9624 | 0.9625 | 0.9624 |
| **Bi-LSTM+CRF** | 0.9631 | 0.9632 | 0.9632 |
| jieba           | 0.8204 | 0.8145 | 0.8174 |
| pkuseg          | 0.8701 | 0.8894 | 0.8796 |
| THULAC          | 0.8428 | 0.8880 | 0.8648 |

## 实验分析

首先，实现进行了纵向对比，本次实验主要针对神经网络方法进行实现，构建了不同层结构的Bi-LSTM模型训练对比：在PKU数据集上，我们可以看到3层结构的Bi-LSTM的效果相对较好，但是加上CRF层后，1层的效果反而最好。在MSR数据集上，可以看到2层的Bi-LSTM效果最好，加上CRF层后3层的效果最好。总体来看，模型的层级结构对效果并没有什么明显的规律，性能的好坏可能更取决于一些超参数的设定，但是这些参数的设定往往具有一定的随机性，只能凭借着经验取调试。

其次，实验进行了横向对比，将前一次实验的传统方法，以及一些经典的开源分词包一同对比，观察不同模型间的效果差异：

- 在PKU数据集上，在传统算法中，CRF的效果十分显著相比其他算法的效果更优，Bi-LSTM以及添加CRF层的效果比传统语言模型和jieba和THULAC开源分词库的效果好，但是比只有CRF和pkuseg的效果略差。原因可能是Bi-LSTM因为算力受限，只训练了50个epoch，没有达到最优的实验结果。
- 在MSR数据集上，在传统算法中，CRF的效果仍然十分显著，相比其他算法的效果更优。但是在该数据集上Bi-LSTM以及添加CRF层的效果却优于列举出的所有开源分词工具以及传统算法。但是实际效果略差于只使用CRF，具体原因同PKU数据集的情况。